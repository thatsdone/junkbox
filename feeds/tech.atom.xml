<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>That's Done! - tech</title><link href="https://thatsdone.github.io/junkbox/" rel="alternate"></link><link href="https://thatsdone.github.io/junkbox/feeds/tech.atom.xml" rel="self"></link><id>https://thatsdone.github.io/junkbox/</id><updated>2020-02-11T21:00:00+09:00</updated><subtitle>thatsdone's (mostly technical) memorandum</subtitle><entry><title>[ja] Kubernetes Patterns</title><link href="https://thatsdone.github.io/junkbox/book_kubernetes_patterns.html" rel="alternate"></link><published>2020-02-11T21:00:00+09:00</published><updated>2020-02-11T21:00:00+09:00</updated><author><name>thatsdone</name></author><id>tag:thatsdone.github.io,2020-02-11:/junkbox/book_kubernetes_patterns.html</id><summary type="html">&lt;p&gt;Kubernetes Patterns - Reusable Elements for Designing Cloud-Native Applications&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://www.amazon.co.jp/Performance-Tools-Addison-Wesley-Professional-Computing/dp/0136554822/"&gt;BPF本&lt;/a&gt;の話も書きかけなのですが、そういえば同僚がSan Diego でもらってきた本の中に&lt;a href="https://www.amazon.co.jp/dp/1492050288"&gt;Kubernetes Patterns: Reusable Elements for Designing Cloud-Native Applications&lt;/a&gt;もありました。&lt;/p&gt;
&lt;p&gt;同じく章構成はこんな感じになっています。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    1. Introduction

Part I : Foundation Patterns
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;まずは基本パターン…というよりは、見てわかる通り、k8s を使いこなすにあたって押さえておくべき基本概念ですね。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    2 Predcitable Dememands
    3 Declarative Deployments
    4 Health Probe
    5 Managed Lifecycle
    6 Automated Placement

Part II : Behavioral Patterns
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;プログラムやサービスの挙動に応じたパターン分類。だいたい名が体を表しているように思いますが、ぱっと見て11のStateful Serviceと13のSelf Awarenessの違いって何よ？と思ったのですが、Self Awarenessのほうは、コンテナが自分が動ているpodを意識する必要があるようなケースのためのものです。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    7 Batch Job
    8 Periodic Job
    9 Daemon Service
    10 Singleton Service
    11 Stateful Service
    12 Service Discovery
    13 Self Awareness

Part III : Structural Patterns
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Part IIIはプログラムやサービスの構造に基づいたパターン分類。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    14 Init Container
    15 Side Car
    16 Adapter
    17 Ambasaddor

Part IV : Configuration Patterns
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;プログラムやサービスの設定情報をどう持ってまわるか？に基づいたパターン分類。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    18 EnvVar Configuration
    19 Confiuration Resource
    20 Immutable Configuration
    21 Configuration Template

Part V : Advanced Patterns
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;進んだトピック。22のControllerと23のOperatorは、いわゆる kubernetes のController/Operatorの解説、24はkubernetesによってアプリケーションをスケールさせる方法、最後の25はここまでの話題とは少し毛色が変わってkubernetes clusterの中でイメージを維持管理する方法論です。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    22 Controller
    23 Operator
    24 Elastic Scale
    25 Image Builder

    Aferword
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;まとめ。&lt;/p&gt;
&lt;p&gt;さて、ここまでざっと本の構造を眺めただけなので、ちゃんと読まなくては(笑)&lt;/p&gt;</content><category term="tech"></category></entry><entry><title>[ja] BPF Performance Tools - Brendan Gregg</title><link href="https://thatsdone.github.io/junkbox/book_bpf_performance_tools.html" rel="alternate"></link><published>2020-01-29T22:30:00+09:00</published><updated>2020-01-29T22:30:00+09:00</updated><author><name>thatsdone</name></author><id>tag:thatsdone.github.io,2020-01-29:/junkbox/book_bpf_performance_tools.html</id><summary type="html">&lt;p&gt;Linux System and Application Observability by BPF&lt;/p&gt;</summary><content type="html">&lt;p&gt;海外出張しているうちに、Brendan Gregg の "&lt;a href="https://www.amazon.co.jp/Performance-Tools-Addison-Wesley-Professional-Computing/dp/0136554822/"&gt;BPF Performance Tools&lt;/a&gt;" が届いていました。:)&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.amazon.co.jp/dp/0133390098"&gt;前著&lt;/a&gt;の&lt;a href="https://thatsdone.github.io/junkbox/methodologies_of_systems_performance.html"&gt;まとめ&lt;/a&gt;を書いている最中ではあるのですが、こっちもまとめようかと思います。(つまり、やっぱり書きかけ…)&lt;/p&gt;
&lt;h2&gt;本書の構成&lt;/h2&gt;
&lt;p&gt;まず、目次の章レベルの構成は以下のような感じになっています。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Part I : Technologies
    1 Introduction
    2 Technology Background
    3 Performance Analysis
    4 BCC
    5 bpftrace
Part II : Using BPF Tools
    6 CPUs
    7 Memory
    8 Filesystems
    9 Disk I/O
    10 Networking
    11 Security
    12 Laguages
    13 Applications
    14 Kernel
    15 Containers
    16 Hypervisors
Part III : Additional Topics
    17 Other BPF Performance Tools
    18 Tips, Tricks and Common Problems
Part IV : Appendixes
    A BPF Trace One-Liners
    B BPF Trace Cheat Sheet
    C BCC Tool Development
    D C BPF
    E BPF Instructions
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Part Iで大事なのは3章の3.2節"Performance Methodologies"でしょうか。この3.2節に相当する内容は、前著では2章すべてをあててかなり包括的に性能解析の考え方を説明していたのですが、本書では必要最小限のかなりコンパクトな量におさえています。
Part Iではそのほか、1章で全体像、2章でBPFそのものと関連コンポーネントの紹介、4章で"BCC" (BPF Compiler Collection)と題してBPF関連の開発ツールについての紹介、5章が一番よく使われるツールで"bpftool"の詳しい解説になっています。&lt;/p&gt;
&lt;p&gt;Part IIは、前著でいうと5章以降の、"Application"や"CPU"といった具体的な切り口に即したBPF関連ツールの使い方の紹介です。なお、15章のContainersと16章のHypervisorsは、前著にも含まれないトピック自体新しい内容なので、最初は全体を流す人も読んだほうがいいかもしれません。(というか私もそうします(笑))&lt;/p&gt;
&lt;p&gt;Part IIIの17章は "Other BPF Performance Tools" とはなっているのですが、Prometheus等のモニタリングツールとの組みあわせや、kubernetes との連携話もあり、読み飛ばせません。また、18章も "Tips, Tricks and Common Problems" というタイトルが示すように、実用上おさえておきたい勘所が載っているようです。&lt;/p&gt;
&lt;p&gt;ところで、ここまであたかも読了したような書きぶりですが、読みながらメモっています。
なので、当分は更新が続くと思います。&lt;/p&gt;
&lt;h2&gt;留意事項:Ubuntu 18.04(Bionic)でのインストール&lt;/h2&gt;
&lt;p&gt;本書も&lt;a href="https://www.amazon.co.jp/dp/477419607X"&gt;武内さんの本&lt;/a&gt;と同じように「試して理解」するのが重要だと思いますが、現時点でUbuntuで使いたい人に、インストールで一点留意事項があります。&lt;/p&gt;
&lt;p&gt;まず、インストール方法は4.3節の"BCC Installation"で各種distroでのインストール方法が解説されています。&lt;/p&gt;
&lt;p&gt;Ubuntuの場合はuniverseにbpfcc-toolsというパッケージ名で入っているのでこれを入れてもよいのですが、特に 18.04(Bionic)付属のものは古いので、できれば新しいものを使いたいところです。4.3.2 節のUbuntu用の説明では、https://repo.iovisor.org/ の apt-line が紹介されているのですが、'20/2時点でメンテナンスが止まっているようです。&lt;/p&gt;
&lt;p&gt;調べてみたところ、Colin Ian Kingさんがメンテしているppaから最新版が入れられるようなので、どうしても自前でビルドしたい人以外はこちらを使うとよいでしょう。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://launchpad.net/~colin-king/+archive/ubuntu/bpftrace-backports"&gt;https://launchpad.net/~colin-king/+archive/ubuntu/bpftrace-backports&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;以下の手順でインストールできます。(bpftraceも一緒に入れてください)&lt;/p&gt;
&lt;p&gt;```bash
sudo add-apt-repository ppa:colin-king/bpftrace-backports
sudo apt-get update&lt;/p&gt;
&lt;p&gt;sudo apt-get install bpfcc-tools bpftrace
```&lt;/p&gt;
&lt;h2&gt;性能分析の方法論&lt;/h2&gt;
&lt;p&gt;一番大事なところ(だと私は思う)、性能分析の方法論は3.2節で解説されています。&lt;/p&gt;
&lt;p&gt;具体的には以下の通りですが、1) 問題を定義する、2) 段階的詳細化、3) 構造の理解の上でリソースの状態の分析…と、もっともな内容になっています。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;3.2.1節 Workload Characterization&lt;/li&gt;
&lt;li&gt;3.2.2節 Drill-Analysis&lt;/li&gt;
&lt;li&gt;3.2.3節 USE Method&lt;/li&gt;
&lt;li&gt;3.2.4節 Checklists&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;チェックリストで定型化するのはサポート部隊等でよく取られる手段ですが、直後の3.3節ではLinuxの場合に1分でできるチェックリストの実例ということで以下のようなコマンドが挙がっています。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;uptime&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dmesg | tail&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;vmstat 1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mpstat -P ALL 1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pidstat 1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;iostat -xz 1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;free -m&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sar -n DEV 1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sar -n TCP,ETCP 1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;top&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;本書で詳細に解説される bpfcc-tools 付属の各種スクリプトやツールで同等のことはできるのですが、
上記は大体どんな環境にも入っていますし、併用するのも有益でしょう…という記述もあります。&lt;/p&gt;</content><category term="tech"></category></entry><entry><title>[ja] Methodologies of Systems Performance - Brendan Gregg</title><link href="https://thatsdone.github.io/junkbox/book_methodologies_of_systems_performance.html" rel="alternate"></link><published>2020-01-14T00:01:00+09:00</published><updated>2020-01-14T00:01:00+09:00</updated><author><name>thatsdone</name></author><id>tag:thatsdone.github.io,2020-01-14:/junkbox/book_methodologies_of_systems_performance.html</id><summary type="html">&lt;p&gt;Methodologies of Peformance Analysis&lt;/p&gt;</summary><content type="html">&lt;p&gt;Brendan Gregg の "&lt;a href="https://www.amazon.co.jp/dp/0133390098"&gt;Systems Performance: Enterprise and the Cloud&lt;/a&gt;" という本があります。
(翻訳は&lt;a href="https://www.amazon.co.jp/dp/4873117909/"&gt;こちら&lt;/a&gt;) 言わずと知れた DTrace の作者が書いた本で、
全体的な考え方から、CPU・メモリ…等と、具体的な観点ごとに包括的かつ詳細に解説されているので非常によい本です。
軽い勉強会みたいなやつで使おうと思って、まずは方法論(Methodology)が書いてある2章のまとめを作っています。
…が、書いてみたら、結局、目次を追っていくのが一番いいのかなー…という結論に（笑）&lt;/p&gt;
&lt;p&gt;なお、昨年末に"&lt;a href="https://www.amazon.co.jp/dp/0136554822/"&gt;BPF Performance Tools&lt;/a&gt;"という新しい本も出ていて買ったのですが、
私は発送待ち状態です。いつ日本に来るんでしょうか？(苦笑)
まあ、eBPF/XDPについては&lt;a href="https://www.amazon.co.jp/Linux-Observability-Bpf-Programming-Performance/dp/1492050202/"&gt;これ&lt;/a&gt;
も読んだので、まあぼちぼちでいいっちゃいいのですが。(笑)&lt;/p&gt;
&lt;h1&gt;一番大事なところ - 方法論の章(2章)の構成&lt;/h1&gt;
&lt;p&gt;方法論(Methodology)は2章になります。
この章だけでけっこうな分量になるので、まずは全体を俯瞰するという意味で、目次構成を眺めるだけでも意味があるでしょう。
目次の構成をそのまま引用しながらまとめていきます。少し長いですが、落ち着いて眺めてみると頭が整理できると思います。&lt;/p&gt;
&lt;p&gt;なお、著者本人は、冒頭でこの章をざっくりまとめると以下の３点であると書いています。
2.5節の具体的な方法論と、これらを使うときに使う具体的な Metric の２点が大事なのであって、
他はみんなこの２点を使うための背景知識なのだというわけです。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Background&lt;/li&gt;
&lt;li&gt;Methodology&lt;/li&gt;
&lt;li&gt;Metrics&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;以下、２章の目次にしたがって見ていきます。(ただし、まだ書きかけ)&lt;/p&gt;
&lt;h2&gt;2. Methodology ★一番大事な章★&lt;/h2&gt;
&lt;h3&gt;2.1 Terminology ＃ まずは用語定義&lt;/h3&gt;
&lt;h3&gt;2.2 Models ＃ モデル&lt;/h3&gt;
&lt;h4&gt;2.2.1 Systems Under Test&lt;/h4&gt;
&lt;p&gt;評価・分析するシステム自体のモデル化しておく。いわゆるSUT。&lt;/p&gt;
&lt;h4&gt;2.2.2 Queueing System&lt;/h4&gt;
&lt;p&gt;待ち行列理論 = 数理モデルの基本&lt;/p&gt;
&lt;p&gt;ちなみにこんな本もありますね。&lt;a href="https://www.amazon.co.jp/Performance-Modeling-Design-Computer-Systems/dp/1107027500"&gt;Performance Modeling and Design of Computer Systems: Queueing Theory in Action&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;2.3 Concepts ＃ 基本概念&lt;/h3&gt;
&lt;p&gt;この節、個人的には項目の選択とか並びが ad hoc すぎるのではないか？という感がありますが、それは別途整理するとして、並んでいる順番に見ていきます。&lt;/p&gt;
&lt;h4&gt;2.3.1 Latency&lt;/h4&gt;
&lt;p&gt;一言で「通信遅延」と言っても、測定する場所によって、例えばコネクション接続+データ転送+処理時間…等分解されるのに注意。&lt;/p&gt;
&lt;h4&gt;2.3.2 Time-Scales&lt;/h4&gt;
&lt;p&gt;CPUの命令サイクル、メモリアクセス、DISKアクセス…等、モノによってかかる時間のスケールが違うのに注意。&lt;/p&gt;
&lt;h4&gt;2.3.3 Trade-offs&lt;/h4&gt;
&lt;p&gt;例えば、I/OサイズとI/O性能・I/Oパターンの関係等、両立しないものの間のトレードオフを知ること。&lt;/p&gt;
&lt;h4&gt;2.3.4 Tuning Efforts&lt;/h4&gt;
&lt;p&gt;アプリ～MW～OS～ハードのどのレイヤで性能チューニングを施すのか？一般論としては(アプリに近い)上のレイヤで実施するほど効果は高い。&lt;/p&gt;
&lt;h4&gt;2.3.5 Level of Appropriateness&lt;/h4&gt;
&lt;p&gt;性能分析、チューニングにどこまでコストをかけて深堀りするのかは組織としての投資対効果による。&lt;/p&gt;
&lt;h4&gt;2.3.6 Point-in-Time Recommendations&lt;/h4&gt;
&lt;p&gt;チューニングパラメータの推奨値は、条件によって変わるものなので「その時点のもの」(point-in-time)と思うべし。&lt;/p&gt;
&lt;h4&gt;2.3.7 Load versus Architecture&lt;/h4&gt;
&lt;p&gt;システムの性能に影響するのは個々のソフトの「設定値」だけでなく、システムの構造（アーキテクチャ）に由来することもある。&lt;/p&gt;
&lt;h4&gt;2.3.8 Scalability&lt;/h4&gt;
&lt;p&gt;スケーラビリティ＝負荷量に対する性能値のふるまい。ふるまいの変化は、スループットの場合はリニアな伸びが変わるところ、レスポンスは一定値（≒リニア）から徐々に劣化が始まるところで見える。典型的な理由は、(なんらかの)リソースの utilization が 100%に達すること(saturation)。&lt;/p&gt;
&lt;h4&gt;2.3.9 Known-Unknowns&lt;/h4&gt;
&lt;p&gt;いわゆるknown-known/known-unknown/unknown-unknown。性能評価を進めるにしたがって、unknown-unknownに気づいていくのに注意。&lt;/p&gt;
&lt;h4&gt;2.3.10 Metrics&lt;/h4&gt;
&lt;p&gt;実際に見る具体的な指標。例としては、IOPS、troughput、utilization、latenc等々。忘れてはいけない大事な点として、1) metricの採取自体にもコストがかかること、2) metricの定義や実装そのものに信頼がないようなケースもあること。&lt;/p&gt;
&lt;h4&gt;2.3.11 Utilization&lt;/h4&gt;
&lt;p&gt;利用率には「時間(time)ベース」と「容量(capacity)ベース」の２つがある。前者は単位時間あたりに仕事をしていた時間(busy率)で、後者は処理可能な容量に対する割合。特に前者のbusy率の場合、リソースによっては多重処理が可能なケースもあるので、utilization が100%であっても限界とは限らないのに注意が必要。&lt;/p&gt;
&lt;p&gt;cloud (というか、仮想化)環境の場合には、non-idle time という見方をしたほうがよいという考え方もある。&lt;/p&gt;
&lt;h4&gt;2.3.12 Saturation&lt;/h4&gt;
&lt;p&gt;saturation (飽和)状態とは、処理可能な量を超えて、どの程度のリクエスト(仕事)量が流入しているかを示す程度。処理しきれないリクエストは、待ち行列につながることになる。&lt;/p&gt;
&lt;h4&gt;2.3.13 Profiling&lt;/h4&gt;
&lt;p&gt;一般論としては、調べて理解できるような対象システムの「描像」を得ること。実際のシステムの Profiling では、典型的にはサンプリングが基本であって、(サンプル間隔しだいだが)得られる描像は荒い（疎な）ものになるの注意。&lt;/p&gt;
&lt;h4&gt;2.3.14 Caching&lt;/h4&gt;
&lt;p&gt;本書では後ろの方でキャッシングとバッファリングの違いの話も出てきますが、ここではキャッシュのヒット率と性能の関係、キャッシュのアルゴリズム(MRU/LRU/MFU/LFU)や、キャッシュされたデータのCold/Hot/Warmという分類(と、キャッシュ暖かさ(Warmth)という用語)が出てきます。&lt;/p&gt;
&lt;h3&gt;2.4 Perspectives ＃ 全体像&lt;/h3&gt;
&lt;p&gt;性能分析には、大きく、1. Resource Analysis と 2. Workload Analysis の2つの側面がある。&lt;/p&gt;
&lt;p&gt;1.の Resource Analysisには文字通りリソースの利用状況の分析であり、さらに a) 性能問題の調査と、b) Capacity Planning が含まれる。&lt;/p&gt;
&lt;p&gt;2.の Workload Analysisはアプリケーションの構造を鑑みて指標(SLIかな)をどう定義するのか？という話で、典型的には Latency(Response)とThroughputが含まれる。&lt;/p&gt;
&lt;h3&gt;2.5 Methodology ＃ 方法論（★一番大事なところ★）&lt;/h3&gt;
&lt;p&gt;この節は一番大事なところなのですが、2.3 Concepts と同様に、並んでいる順番が少し ad hoc すぎないか？という気がしています。&lt;/p&gt;
&lt;h4&gt;2.5.1 Streetlight Anti-Method&lt;/h4&gt;
&lt;p&gt;Anti-Method(やっちゃダメ)な例。意図的な方法論がないケースのこと。適当に探してなんとなく見つかったツールで測定した指標を使うということで、検出された問題は実際のところは問題なこともあるし問題でないこともある。&lt;/p&gt;
&lt;h4&gt;2.5.2 Random Change Anti-Method&lt;/h4&gt;
&lt;p&gt;これも Anti-Method。原因になっていそうポイントをランダムに想定し、その条件を問題が消えるまで変え続けるということ。&lt;/p&gt;
&lt;h4&gt;2.5.3. Blame-Someone-Else Anti-Method&lt;/h4&gt;
&lt;p&gt;同じく Anti-Method。自分の担当範囲外の部分を見つけて、そこに原因があるという仮説を立てて担当チームに押し付ける。(ごくまれによく採用される方法論...gkbr)&lt;/p&gt;
&lt;h4&gt;2.5.4 Ad Hoc Checklist Method&lt;/h4&gt;
&lt;p&gt;定型のチェックリストにしたがう方法。チェックリスト自体は最短時間で多くの範囲をカバーできるが、あくまでその時点での推奨であって、頻繁に更新する必要があるのに注意。&lt;/p&gt;
&lt;h4&gt;2.5.5 Problem Statement ★最重要★&lt;/h4&gt;
&lt;p&gt;新しい問題に取り組むときには最初にとるべき方法。以下のような手順で、問題を具体的に書き下して定義していきます。これによって、問題点がわかることも多いです。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;性能問題があると考えた理由は何か？&lt;/li&gt;
&lt;li&gt;今まで想定どおりに動いていたか？&lt;/li&gt;
&lt;li&gt;最近何か変えたか？&lt;/li&gt;
&lt;li&gt;問題はlatencyかthroughputの指標で表せるか？&lt;/li&gt;
&lt;li&gt;その問題は、他の人やアプリケーションに影響を及ぼしているのか？それとも自分だけか？&lt;/li&gt;
&lt;li&gt;環境は？どんなソフトとハードを使っているのか？バージョンは？設定は？&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;2.5.6 Scientific Method ★重要★&lt;/h4&gt;
&lt;p&gt;通常の自然科学の研究でとるアプローチ。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;課題設定(Question)&lt;/li&gt;
&lt;li&gt;仮説を立てる(Hypothetis)&lt;/li&gt;
&lt;li&gt;予想をたてる(Prediction)&lt;/li&gt;
&lt;li&gt;テスト(Test)&lt;/li&gt;
&lt;li&gt;分析(Analysis)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;最初の 'Question' は 2.5.5の Problem Statement であって、これが出発点になる。&lt;/p&gt;
&lt;h4&gt;2.5.7 Diagnosis Cycle  ★重要★&lt;/h4&gt;
&lt;p&gt;Scientific Method と似ているが。仮説をたてる → 計測する → 分析する →　新しい仮説をたてる…という分析的なアプローチ。&lt;/p&gt;
&lt;h4&gt;2.5.8 Tools Method&lt;/h4&gt;
&lt;p&gt;手順は「使えるツールのリストを作る → 各ツールで得られる有用なmetricの一覧を作る → 各metricの解釈のルールを作る」。これが完璧というわけではないし、十分とは言えないこともあるが、現実的にはこの方法でリソースのボトルネックやエラー等の問題を検出できる。&lt;/p&gt;
&lt;h4&gt;2.5.9 The USE Method ★重要★&lt;/h4&gt;
&lt;p&gt;まず特定のリソースに着目、当該リソース関連のErrorがあるか？、Utilization は高いか？Saturationが発生しているか？の十番で事象の発生有無をチェックし、検出した事象が原因なのかどうか検討する。原因でなければ次のリソースに着目するという手順をとる。&lt;/p&gt;
&lt;p&gt;着目すべきリソースは、リソースの一覧表を使う(CPU/Memory/Network/Storage/Controller等)、機能ブロック図(例として図2.13)から考える方法がある。&lt;/p&gt;
&lt;p&gt;リソースの種別ごとに様々な metric がある。(表2.5と表2.6)手元のツールで取得できない metric は known-unknownとして意識しておくべき。&lt;/p&gt;
&lt;p&gt;CPUのようなハードウェアリソース以外に「ソフトウェアリソース」がある。例えば、mutex lock の衝突数等、thread poolの空き状況等。&lt;/p&gt;
&lt;p&gt;解釈の例&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Utilization&lt;ul&gt;
&lt;li&gt;きちんと評価するには、待ち行列を使って考えるべし。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Saturation&lt;ul&gt;
&lt;li&gt;飽和状態が発生しているということは問題な可能性がある。待ちキューの長さ滞留時間を調べる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Error&lt;ul&gt;
&lt;li&gt;エラーのカウンタが0でなく、数値が増え続けているのであれば調べる価値がある。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;2.5.10 Workload Characterization&lt;/h4&gt;
&lt;p&gt;「ワークロードの説明」をしておくのは、問題点を明らかにするための良い方法。以下の4つを問うことによって説明できる。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Who : 誰が負荷を発生させているのか？ PID？UID？remote IP address？&lt;/li&gt;
&lt;li&gt;Why : なぜその負荷が発生しているのか？code pathをstack traceで調べる？&lt;/li&gt;
&lt;li&gt;What : その負荷の特徴は？IOPS？throughput？方向(read/write) ？分散(や標準偏差)も込みで。&lt;/li&gt;
&lt;li&gt;How : その負荷には時間に依存したパターンがあるか？日時など。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;2.5.11 Drill-Down Analysis&lt;/h4&gt;
&lt;p&gt;いわゆる段階的詳細化。以下の３段階がある。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Monitoring&lt;ul&gt;
&lt;li&gt;継続的にリソースの監視を行う。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Identification&lt;ul&gt;
&lt;li&gt;特定のリソースの挙動によって、ありうるボトルネックを特定する。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Analysis&lt;ul&gt;
&lt;li&gt;根本原因の特定と問題の定量化を試みる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;「なぜは５回くりかえせ」…って、某自動車メーカーでも言っていますね。
ただし「５回」自体にはあまり意味はなくて、例えば "human error" で「なぜ」の追及をやめるな…等、あります。&lt;/p&gt;
&lt;h4&gt;2.5.12 Latency Analysis&lt;/h4&gt;
&lt;p&gt;１つのリクエストの処理を細かい部分処理に分解・分析していく。根本原因を特定・定量化できるように、最も時間のかかっている部分処理を調べる。&lt;/p&gt;
&lt;h4&gt;2.5.13 Method R (by Oracle)&lt;/h4&gt;
&lt;p&gt;Oracleのツール固有の話。SQL Query の 2.5.12 Latency Analysisに相当する。&lt;/p&gt;
&lt;h4&gt;2.5.14 Event Tracing&lt;/h4&gt;
&lt;p&gt;システムの動きは離散的なイベントの処理ということができる。ここでいうイベントとは、CPU命令とか、DISKコマンドとか、Networkパケットのような低レイヤのものから、SQLクエリなどもイベントとみなせる。&lt;/p&gt;
&lt;p&gt;性能分析とは、これらのイベントのサマリを検討することであり、例えば、単位時間あたりの操作、単位時間当たりのデータ量などが含まれるが、
サマリ（集計値）に詳細が埋もれてしまうこともある。&lt;/p&gt;
&lt;p&gt;例として、systemcallのトレース(strace)、I/Oトレース(Solarisのiosnoop)、パケットダンプ(tcpdump)が挙げられている。
…が、perf (というか BPF/eBPFや、昔は systemtap)を使うことによって、多彩な種類のイベントをイベント単位で知らべることもできる。&lt;/p&gt;
&lt;h4&gt;2.5.15 Baseline Statistics&lt;/h4&gt;
&lt;p&gt;基準になる性能値とその時の各種リソースの値等を採取しておくこと。&lt;/p&gt;
&lt;p&gt;これはまあPOCするときの基本ですね。&lt;/p&gt;
&lt;h4&gt;2.5.16 Static Peformance Tuning&lt;/h4&gt;
&lt;p&gt;静的性能チューニングは、例えば、NICのportが意図のリンク速度でLINK UPしているか？等の設定、状態を確認していくこと。&lt;/p&gt;
&lt;h4&gt;2.5.17 Cache Tuning&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;そもそもキャッシュ機能が有効になっているか？&lt;/li&gt;
&lt;li&gt;キャッシュのヒット率/ミス率&lt;/li&gt;
&lt;li&gt;キャッシュサイズが動的に変わる場合の現在のサイズ&lt;/li&gt;
&lt;li&gt;複数レイヤにキャッシュがある場合、処理をしている一番近くでキャッシュが効いているか？&lt;/li&gt;
&lt;li&gt;CPUキャッシュ(L1/L2/L3)の場合、レイヤごとに削れるレイテンシと効果が異なってくる。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;2.5.18 Micro-Benchmarking&lt;/h4&gt;
&lt;p&gt;アプリケーションレベルだと負荷自体が複雑になりすぎて問題点がわかりにくいことも多いが、「ピンポン通信」等の、これ以上分解できないくらい細かい視点でのベンチマーク。&lt;/p&gt;
&lt;h3&gt;2.6 Modeling&lt;/h3&gt;
&lt;h4&gt;2.6.1 Enterprise versus Cloud&lt;/h4&gt;
&lt;p&gt;TBD&lt;/p&gt;
&lt;h4&gt;2.6.2 Visual Identification&lt;/h4&gt;
&lt;p&gt;性能特性をグラフにしてみると、特徴的なパターンがいくつかある。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Linear scalability (線形)&lt;/li&gt;
&lt;li&gt;Contention (競合)&lt;/li&gt;
&lt;li&gt;Coherence　(干渉)&lt;/li&gt;
&lt;li&gt;Knee point (適切な日本語が見つからないのだが、まあ折れているということ)&lt;/li&gt;
&lt;li&gt;Scalability Ceiling (天井にあたったように水平になってしまうこと)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;2.6.3 Amdahl's Law of Scalability&lt;/h4&gt;
&lt;p&gt;いわゆるアムダールの法則。&lt;/p&gt;
&lt;p&gt;C(N) = N/(1 + α(N-1))&lt;/p&gt;
&lt;h4&gt;2.6.4 Universal Scalability Law&lt;/h4&gt;
&lt;p&gt;C(N) = N/(α(N-1) + βN(N-1))&lt;/p&gt;
&lt;h4&gt;2.6.5 Queueing Theory - 待ち行列理論&lt;/h4&gt;
&lt;p&gt;待ち行列大事。典型的には以下くらい？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;M/M/1&lt;/li&gt;
&lt;li&gt;M/M/c&lt;/li&gt;
&lt;li&gt;M/G/1&lt;/li&gt;
&lt;li&gt;M/D/1    &lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;2.7 Capacity Planning&lt;/h3&gt;
&lt;p&gt;TBD&lt;/p&gt;
&lt;h4&gt;2.7.1. Resource Limits&lt;/h4&gt;
&lt;h4&gt;2.7.2 Factor Analysis&lt;/h4&gt;
&lt;h4&gt;2.7.3 Scaling Solutions&lt;/h4&gt;
&lt;h3&gt;2.8 Statistics&lt;/h3&gt;
&lt;p&gt;統計も大事。だが、TBD。&lt;/p&gt;
&lt;h4&gt;2.8.1 Quantifying Performance&lt;/h4&gt;
&lt;h4&gt;2.8.2 Averages&lt;/h4&gt;
&lt;p&gt;「平均値」って何種類もあるって意識していただろうか？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;アルキメデスの3平均&lt;ul&gt;
&lt;li&gt;Arithmetric - 算術平均(一番普通に使うやつ)&lt;/li&gt;
&lt;li&gt;Geometric - 幾何平均&lt;/li&gt;
&lt;li&gt;Harmonic 調和平均(Fの定義で出てきますね)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Averages over Time&lt;/li&gt;
&lt;li&gt;Decayed Average&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;2.8.3 Standard Deviationos, Percentiles, Median&lt;/h4&gt;
&lt;h4&gt;2.8.4 Coefficient of Variation&lt;/h4&gt;
&lt;h4&gt;2.8.5 Multimodal Distributions&lt;/h4&gt;
&lt;h4&gt;2.8.6 Outliers&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Anomaly???&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;2.9 Monitoring&lt;/h3&gt;
&lt;h4&gt;2.9.1 Time-Based Patterns&lt;/h4&gt;
&lt;h4&gt;2.9.2 Monitoring Products&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Summary-since Boot&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;2.10 Visualizations&lt;/h3&gt;
&lt;h4&gt;2.10.1 Line Chart&lt;/h4&gt;
&lt;h4&gt;2.10.2 Scatter Plots&lt;/h4&gt;
&lt;p&gt;散布図の有用性をちゃんと意識している人って少ないような気がする。&lt;/p&gt;
&lt;h4&gt;2.10.3 Heat Maps&lt;/h4&gt;
&lt;h4&gt;2.10.4 Surface Plot&lt;/h4&gt;
&lt;h4&gt;2.10.5 Visualization Tools&lt;/h4&gt;
&lt;h3&gt;2.11 Exercises&lt;/h3&gt;
&lt;h3&gt;2.12 References&lt;/h3&gt;
&lt;h2&gt;13. Case Study : むかーし、Redis がナニモノかも知らなかった頃の話&lt;/h2&gt;</content><category term="tech"></category></entry><entry><title>[ja] back to basics - SRECon19 EMEA revisited, and beyond</title><link href="https://thatsdone.github.io/junkbox/backtobasics_srecon19emea_revisited.html" rel="alternate"></link><published>2020-01-13T12:21:00+09:00</published><updated>2020-01-13T12:21:00+09:00</updated><author><name>thatsdone</name></author><id>tag:thatsdone.github.io,2020-01-13:/junkbox/backtobasics_srecon19emea_revisited.html</id><summary type="html">&lt;p&gt;SRE Methodologies&lt;/p&gt;</summary><content type="html">&lt;p&gt;さて、SRECon (や、USENIX LISA)では、ここしばらくCore Principles トラックという形で、
SREのチームの作り方やSREチームの運営のしかた…等といった話を多数聞くことができるわけですが、
&lt;a href="https://thatsdone.github.io/junkbox/srecon19emea.html"&gt;前に書いた記事&lt;/a&gt;で少し触れたように、
&lt;a href="https://www.usenix.org/conference/srecon19emea/"&gt;SRECon19EMEA&lt;/a&gt;の特徴だった、
運用まわりで使える確立した方法論の話をもう一回振り返ってみます。&lt;/p&gt;
&lt;h2&gt;まえおき&lt;/h2&gt;
&lt;p&gt;この記事はあと３回更新します。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;まずはポインタの一覧だけ(DONE)&lt;/li&gt;
&lt;li&gt;それぞれ解説(みたいなの)を追加&lt;/li&gt;
&lt;li&gt;SRECon の本筋の Core Princilple の話を追加&lt;/li&gt;
&lt;li&gt;日本発のback to basicな話の事例ということでTPSの話(これは別記事にするかも)&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;運用まわりで使える back to basic な方法論&lt;/h2&gt;
&lt;p&gt;とりあえず、私が現地で聞いたセッションの中で気づいたものの一覧だけ。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Systems Theory -システム理論&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://ja.wikipedia.org/wiki/%E5%88%B6%E5%BE%A1%E7%90%86%E8%AB%96"&gt;wikipedia(ja)&lt;/a&gt; &lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.usenix.org/conference/srecon19emea/presentation/leveson"&gt;SRECon19EMEA セッション&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;Speaker : Prof. Leveson, MIT&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Control Theory - 制御理論&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://ja.wikipedia.org/wiki/%E5%88%B6%E5%BE%A1%E7%90%86%E8%AB%96"&gt;wikipedia(ja)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.usenix.org/conference/srecon19emea/presentation/hahn"&gt;SRECon19EMEA セッション&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;Speaker : Ted Hahn, TCB Technologies, and Mark Hahn, Ciber Global&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Incident Command System - 現場指揮システム&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://ja.wikipedia.org/wiki/%E3%82%A4%E3%83%B3%E3%82%B7%E3%83%87%E3%83%B3%E3%83%88%E3%83%BB%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E3%83%BB%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0"&gt;wikipedia(ja)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.usenix.org/conference/srecon19emea/presentation/hidalgo"&gt;SRECon19EMEA セッション&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;Speaker : Alex Hidalgo and Alex Lee, Squarespace&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Fault Tree Analysis - 故障木解析&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://ja.wikipedia.org/wiki/%E3%83%95%E3%82%A9%E3%83%AB%E3%83%88%E3%83%84%E3%83%AA%E3%83%BC%E8%A7%A3%E6%9E%90"&gt;wikipedia(ja)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.usenix.org/conference/srecon19emea/presentation/falko"&gt;SRECon19EMEA セッション&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;Speaker : Andrey Falko, Lyft&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Formal Verification Method - 形式的検証手法&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://ja.wikipedia.org/wiki/%E5%BD%A2%E5%BC%8F%E7%9A%84%E6%A4%9C%E8%A8%BC"&gt;wikipedia(ja)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.usenix.org/conference/srecon19emea/presentation/khlaaf"&gt;SRECon19EMEA セッション&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;Speaker : Heidy Khlaaf, Adelard LLP&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;SRE Core Principles&lt;/h2&gt;
&lt;p&gt;TBD&lt;/p&gt;
&lt;h2&gt;TPS : Toyota Production System - トヨタ生産方式&lt;/h2&gt;
&lt;p&gt;まずはとりあえず、関連情報のリンクだけ。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;『トヨタ生産方式』ー脱規模の経営をめざしてー (大野耐一・著)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;https://www.amazon.co.jp/dp/4478460019/&lt;/li&gt;
&lt;li&gt;ISBN-10: 4478460019&lt;/li&gt;
&lt;li&gt;ISBN-13: 978-4478460016&lt;/li&gt;
&lt;li&gt;1978年5月25日 初版発行&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;参考&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;トヨタ生産方式のかんばん&lt;a href="https://ja.wikipedia.org/wiki/%E3%82%AB%E3%83%B3%E3%83%90%E3%83%B3"&gt;ja&lt;/a&gt;/&lt;a href="https://en.wikipedia.org/wiki/Kanban"&gt;en&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ソフト開発のカンバン&lt;a href="https://ja.wikipedia.org/wiki/%E3%81%8B%E3%82%93%E3%81%B0%E3%82%93_(%E3%82%BD%E3%83%95%E3%83%88%E3%82%A6%E3%82%A7%E3%82%A2%E9%96%8B%E7%99%BA)"&gt;ja&lt;/a&gt;/&lt;a href="https://en.wikipedia.org/wiki/Kanban_(development)"&gt;en&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</content><category term="tech"></category></entry><entry><title>[ja] SRECon19 EMEA</title><link href="https://thatsdone.github.io/junkbox/srecon19emea.html" rel="alternate"></link><published>2019-10-03T14:30:00+09:00</published><updated>2019-10-03T14:30:00+09:00</updated><author><name>thatsdone</name></author><id>tag:thatsdone.github.io,2019-10-03:/junkbox/srecon19emea.html</id><summary type="html">&lt;p&gt;SRECon19EMEA&lt;/p&gt;</summary><content type="html">&lt;p&gt;アイルランドのダブリンで開催中の &lt;a href="https://www.usenix.org/conference/srecon19emea/"&gt;SRECon19EMEA&lt;/a&gt; に来ています。&lt;/p&gt;
&lt;p&gt;ダブリンは初めてで、気温をみて寒そう…とは思っていたのですが、10月頭でもう冬みたいな恰好をしている人が多いとは想像しておらず、
正直、外は寒いです(苦笑)&lt;/p&gt;
&lt;p&gt;初日で一番面白かったのはGoogleの Todd Underwood さんの以下のセッションでしょうか。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.usenix.org/conference/srecon19emea/presentation/underwood"&gt;All of Our ML Ideas Are Bad (and We Should Feel Bad)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;MLを使って運用をラクにしたい…というのはけっこう誰でも考える話で、適用対象としては例えば以下のようなものがあるでしょう&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Categorizing/Prioritizing Tickets&lt;/li&gt;
&lt;li&gt;Root Cause Analysis&lt;/li&gt;
&lt;li&gt;Canary Analysis&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;しかし、実際に使ってみると...&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;(MLよりも)もっといい方法ある&lt;/li&gt;
&lt;li&gt;データが足りない&lt;/li&gt;
&lt;li&gt;ラベル付きのデータが足りない&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;といった理由でうまくいかないことがよくあります。&lt;/p&gt;
&lt;p&gt;Todd さんは、これは流行りのやり方を、深く考えずにそのまま使おうとするからだ…と言います。
よく言われる ML というのは、Marketing ML だと。&lt;/p&gt;
&lt;p&gt;Todd さんのおすすめはこんなふうにまとめられます。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Think&lt;ul&gt;
&lt;li&gt;あなたのアプリ、インフラ、お客さんをよく知る人に話を聞きましょう。&lt;/li&gt;
&lt;li&gt;そして、それらを理解するためのアイデアを出すためにブレストをしましょう。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Gather&lt;ul&gt;
&lt;li&gt;まずはデータを一か所にあつめる。&lt;/li&gt;
&lt;li&gt;整理してみないとなにもできないので、とにかく整理する。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Learn&lt;ul&gt;
&lt;li&gt;まずは基本を押さえましょう。&lt;/li&gt;
&lt;li&gt;MLワークロードを動かすプラットフォームは既にたくさんあるので、こういうものを知りましょう。&lt;/li&gt;
&lt;li&gt;そして、集めたデータを使ってプロトタイプをやってみましょう。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;もっと先まで踏み込む場合は&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ontology&lt;/li&gt;
&lt;li&gt;Epistemology&lt;/li&gt;
&lt;li&gt;Metaphysics&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;の３点を挙げていました。用語は難しいですが、一言で言うと「自分の頭で本質をよく考えろ」ってことですね。 :)
具体的にこうしたらうまくいっているよ…という事例紹介ではありませんが、考え方として、私にはとても参考になったtalkでした。&lt;/p&gt;
&lt;p&gt;Day1 だけでも他にもいろいろ興味深い講演がありました。
例えば、Network trouble の解析の紹介で、よく聞いてみたら eBPF でがんばってCloud Providerにも認めさせたぜ...という
「よくある」話だったりとか(笑)
ぼちぼち更新しようかと思います。&lt;/p&gt;
&lt;p&gt;Stay Tuned ! :)&lt;/p&gt;
&lt;p&gt;2019/10/04 (Dublin現地時間)追記&lt;/p&gt;
&lt;p&gt;SRECon19EMEA、無事に終了しました。
ハリケーンが来ていてアイルランド直撃が予測されいたのですが、大した影響なく済んでよかったです。&lt;/p&gt;
&lt;p&gt;closing での主催者の話によると、今回の出席者は約700名とのこと。3月のNorth Americaでは4桁に届くでしょうか。&lt;/p&gt;
&lt;p&gt;3日間終わってみての所感は、初日のkeynoteのLeverson教授の Systems Theory からはじまり、
Control Theory (制御理論)、Fault Tree Analysis といった、数十年前に確立された理論を振り返る話が多かったことです。
果ては一番最後のセッションが Formal Verification Method...ということで、Program Committee の心意気を感じたように思います。&lt;/p&gt;
&lt;p&gt;私は主に Core Principle の Track に出ていました。具体的にこの手法でうまくいったよ…という話もあることはありましたが、
むしろ Silver Bullet はない。利用者のことをよく知り、自分の頭で考えるべし。ついてはその指針は…という話を多く聞くことができました。
現状の私には非常に参考になる話でした。&lt;/p&gt;
&lt;p&gt;3月の SRECon '20 North America はスケジュールの都合で出席できないのですが、来年度もどれかのSREConに顔を出したいと思います。 :)&lt;/p&gt;</content><category term="tech"></category></entry><entry><title>[ja] BGP in the Data Center</title><link href="https://thatsdone.github.io/junkbox/book_bgp_in_the_datacenter.html" rel="alternate"></link><published>2019-09-21T20:00:00+09:00</published><updated>2019-09-21T20:00:00+09:00</updated><author><name>thatsdone</name></author><id>tag:thatsdone.github.io,2019-09-21:/junkbox/book_bgp_in_the_datacenter.html</id><summary type="html">&lt;p&gt;BGP in the Data Center&lt;/p&gt;</summary><content type="html">&lt;p&gt;一部で話題の O'reily の "BGP in the Data Center" を読んだ。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[https://www.oreilly.com/library/view/bgp-in-the/9781491983416/(https://www.oreilly.com/library/view/bgp-in-the/9781491983416/)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;これは面白い…というか、自分が今やってること的にとても勉強になったのでメモ。&lt;/p&gt;
&lt;p&gt;日本語の他の方の記事もけっこうあるようだ。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://foobaron.hatenablog.com/entry/bgp-in-the-data-center-01"&gt;https://foobaron.hatenablog.com/entry/bgp-in-the-data-center-01&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.bobuhiro11.net/2019/03-21-bgp-in-the-data-center.html"&gt;https://blog.bobuhiro11.net/2019/03-21-bgp-in-the-data-center.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;遡ると'14の JANOG33 で Microsoft の人が講演していたりとか。(時期はこの本よりも早い)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.janog.gr.jp/meeting/janog33/program/bgp.html"&gt;https://www.janog.gr.jp/meeting/janog33/program/bgp.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;1. Introduction to Data Center Networks&lt;/h3&gt;
&lt;p&gt;物理構成の話。L3 Leaf-Spine 型のNWの構成のベストプラクティスの解説。&lt;/p&gt;
&lt;h3&gt;2. How BGP Has Benn Adapted to the Data Center&lt;/h3&gt;
&lt;p&gt;物理構成ができたら、その上の routing をどうやるのか？の話。BGP話。&lt;/p&gt;
&lt;p&gt;しかし、BGPの Best Path Algorithm が参照する metric が8つあって、それを覚えるのにこんなのがあるとは知らなかったw
Cisco(当時?)の Denise Fishburne さんが考えたらしい。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;mnemonic&lt;/th&gt;
&lt;th&gt;-&lt;/th&gt;
&lt;th&gt;BGP metric&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Wise&lt;/td&gt;
&lt;td&gt;W&lt;/td&gt;
&lt;td&gt;Weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Lisp&lt;/td&gt;
&lt;td&gt;L&lt;/td&gt;
&lt;td&gt;LOCAL_PREFERENCE&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Lovers&lt;/td&gt;
&lt;td&gt;L&lt;/td&gt;
&lt;td&gt;Locally Originated&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Apply&lt;/td&gt;
&lt;td&gt;A&lt;/td&gt;
&lt;td&gt;AS_PATH&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Oral&lt;/td&gt;
&lt;td&gt;O&lt;/td&gt;
&lt;td&gt;ORIGIN&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Medication&lt;/td&gt;
&lt;td&gt;M&lt;/td&gt;
&lt;td&gt;MED&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Every&lt;/td&gt;
&lt;td&gt;E&lt;/td&gt;
&lt;td&gt;eBGP over iBGP&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Night&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;NextHop IGP Cost&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;(うー、Pelican の調整がまだ不完全で border が出ないな...)&lt;/p&gt;
&lt;h3&gt;3. Building an Automatable BGP Configuration&lt;/h3&gt;
&lt;p&gt;各router (というか、TOR/Leaf/Spine等スイッチ)の BGP 設定は、
愚直に書くと機器ごとに個別の設定や、個別の機器内でも重複した記述が多数出てくるわけだが、
これを自動化のためにカイゼンできるか？の解説。&lt;/p&gt;
&lt;p&gt;Spine側のASNの割り当てはちょっと誤解していたところがあった...&lt;/p&gt;
&lt;h3&gt;4. Reimaging BGP Configuration&lt;/h3&gt;
&lt;p&gt;3章の解説でもろもろ設定を単純化したとして、まだ以下のような pain point がある。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NW機器間(というか、ホストも含むかな...)のインターフェースに付与して管理するのは大変。&lt;/li&gt;
&lt;li&gt;隣(neighbour)のASの定義をいちいち書くのも大変。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一つ目の問題の解決として、(IPv6) Un-Numbered の解説。&lt;/p&gt;
&lt;p&gt;二つめの問題の解決として、remote-as 構文の拡張の external / internal を使う方法の解説。&lt;/p&gt;
&lt;p&gt;ちな、僕が読んだバージョンの p58 の Figure 4-2 の下半分の図は 10.1.1.0/24 じゃなくて、10.1.2.0/24 だと思う。&lt;/p&gt;
&lt;h3&gt;5. BGP Life Cycle Mamagement&lt;/h3&gt;
&lt;p&gt;状態表示でよく使うコマンドのほか、メンテのために停止させたい時の常套手段と、デバッグのやりかた。&lt;/p&gt;
&lt;p&gt;デバッグ用の機能を使って、経路計算のロジックを勉強する…というのもあるのか。&lt;/p&gt;
&lt;h3&gt;6. BGP on the Host&lt;/h3&gt;
&lt;p&gt;この構成で本格的に動かす場合、ホストも BGP をしゃべることになるわけで、
今までのSEとNEという境界もあいまいになるよね…という話。&lt;/p&gt;
&lt;p&gt;そのほか、Anycast 話とか、Dynamic Neighbour とか。&lt;/p&gt;
&lt;p&gt;そういえば、題材に使われている &lt;a href="https://frrouting.org/"&gt;FRR&lt;/a&gt; を使い込む…
というタスクもあったのだが、再開せねば...(とおいめ&lt;/p&gt;</content><category term="tech"></category></entry><entry><title>[ja] Stray Sheep - OpenShift and CloudFoundry</title><link href="https://thatsdone.github.io/junkbox/openshift_and_cloudfoundry.html" rel="alternate"></link><published>2019-09-14T15:01:00+09:00</published><updated>2019-09-14T15:01:00+09:00</updated><author><name>thatsdone</name></author><id>tag:thatsdone.github.io,2019-09-14:/junkbox/openshift_and_cloudfoundry.html</id><summary type="html">&lt;p&gt;Stray Sheep - OpenShift and Cloud Foundry (again?)&lt;/p&gt;</summary><content type="html">&lt;p&gt;こんな記事が話題になっているようだ。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://techcrunch.com/2019/09/12/together-at-last-ibm-brings-cloud-foundry-to-red-hat-openshift/"&gt;IBM brings Cloud Foundry and Red Hat OpenShift together&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;オレPaaSはこれだぜ…といって始まったはずが、kubernetes 使うならOpenShift…に言うことが全然変わり、そしてまた Cloud Foundry ですか…迷える子羊さんだなー…というのが第一印象。&lt;/p&gt;
&lt;p&gt;とはいえ、API(と、それで制御されるざっくりした構造も…かな)だけ維持して、既存のk8sベースのインフラでCF用に作られたアプリケーションを収容できるようにするというのは自然な発想と言えるかなと思うのだが、この動きって最初から計画されていたのか、それとも Cloud Foundry に大々的に投資していたIBMの意向なのか、どちらなんでしょう？
あと、OpenShiftの場合、Kuryr とか使ってOpenStackと並べて動かすみたいな話もあるようだし、ただでさえ重量級な
OpenShiftがますます複雑化しそうな雰囲気なのがちょっと...(とおいめ&lt;/p&gt;
&lt;p&gt;余談だけど、OpenShift の歴史、特に v1 と v2 の頃ってどんなんだっけ？とググっていたらこんな記事も出てきた。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://developer.ibm.com/blogs/a-brief-history-of-red-hat-openshift/"&gt;A brief history of Kubernetes, OpenShift, and IBM&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;これって、8/1付の記事なのだけど、最初の記事が 9/11-12の Cloud Foundry Summit 2019での &lt;em&gt;IBM&lt;/em&gt; による発表の記事なので、情報は先に出ていた...ということですか。&lt;/p&gt;
&lt;p&gt;ところで、１つめの記事から、こんな記事もリンクされていた。&lt;/p&gt;
&lt;p&gt;[With its Kubernetes bet paying off, Cloud Foundry doubles down on developer experience]
(https://techcrunch.com/2019/09/09/with-its-kubernetes-bet-paying-off-cloud-foundry-double-down-on-developer-experience/)&lt;/p&gt;
&lt;p&gt;Fortune 500に載る会社の50%以上がCloud Foundry使っているって本当？…というのはおいておいて、
PivotalもCloud Foundryをk8sの上で動かすぜー…なんて言っていたのね。知りませんでした...orz&lt;/p&gt;
&lt;p&gt;&lt;a href="https://content.pivotal.io/announcements/pivotal-makes-kubernetes-easier-for-developers-and-operators"&gt;Pivotal Makes Kubernetes Easier for Developers and Operators&lt;/a&gt;&lt;/p&gt;</content><category term="tech"></category></entry><entry><title>[ja] On OpenSDS</title><link href="https://thatsdone.github.io/junkbox/opensds.html" rel="alternate"></link><published>2019-09-03T00:00:00+09:00</published><updated>2019-09-03T00:00:00+09:00</updated><author><name>thatsdone</name></author><id>tag:thatsdone.github.io,2019-09-03:/junkbox/opensds.html</id><summary type="html">&lt;p&gt;My recent OpenSDS related activities&lt;/p&gt;</summary><content type="html">&lt;p&gt;最近は趣味と実益を兼ねて &lt;a href="https://opensds.io/"&gt;OpenSDS&lt;/a&gt; をいじっています。&lt;/p&gt;
&lt;p&gt;OpenSDS は、名前からして「また新しい Software Defined Storage の実装ですか？」と聞かれるのですが、実は複数のストレージコントローラをたばねるものです。
block storage から出発して、今はNFSのような file storage や Object Storage もサポートしています。&lt;/p&gt;
&lt;p&gt;その昔いじっていたOpenStackも sub project がたくさんありましたが、OpenSDS もだいぶにぎやかになってきました。&lt;/p&gt;
&lt;p&gt;この中では telemetry と anomaly-detection (仕事的には multi-cloudも) に興味があるのですが、まずは簡単に使えるようにしなくちゃね...ということで、
githubの私のページの activity を見てもらってもわかる通り、
opensds-installer をせっせと直しています。まずは ansible で、helm chart はその次ですかね...&lt;/p&gt;
&lt;p&gt;余談ですが、現在、OpenSDSの認証には OpenStack の Keystone が導入されています。
Keystone の場合、認証した結果に各種関連サービスの endpoint の一覧が返却される
という変わった(?)仕様なのですが、このあたり、どこまで integration するかは
まだやわらかいようです。&lt;/p&gt;</content><category term="tech"></category></entry></feed>